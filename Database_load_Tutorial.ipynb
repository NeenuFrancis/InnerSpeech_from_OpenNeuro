Database_load_Tutorial.ipynb

Text cell <n7U7t8vLzdmQ>
# %% [markdown]
<a   href="https://colab.research.google.com/github//N-Nieto/Inner_Speech_Dataset/blob/master/Database_load_Tutorial.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

Text cell <paw7a25v4CCd>
# %% [markdown]
# Tutorial for load the Inner speech database.

Text cell <ZeJv3XgwUC4R>
# %% [markdown]
## Set up - Download and import required libraries

Code cell <en9HsrNVTtXg>
# %% [code]
#@title Install dependencies 
!git clone https://github.com/N-Nieto/Inner_Speech_Dataset -q
!pip3 install mne -q
Execution output
0KB
	Stream
		[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.4 MB 21.3 MB/s 
		[?25h

Code cell <GySLvxiqUJzX>
# %% [code]
#@title Imports 
import mne 
import warnings
import numpy as np

from google.colab import drive

from Inner_Speech_Dataset.Python_Processing.Data_extractions import  extract_data_from_subject
from Inner_Speech_Dataset.Python_Processing.Data_processing import  select_time_window, transform_for_classificator

np.random.seed(23)

mne.set_log_level(verbose='warning') #to avoid info at terminal
warnings.filterwarnings(action = "ignore", category = DeprecationWarning ) 
warnings.filterwarnings(action = "ignore", category = FutureWarning ) 

Text cell <gcXsT133Chus>
# %% [markdown]
## Data Loading.

Code cell <C8k9XNR-TwXp>
# %% [code]
# Mount drive with data. You have to download and store the dataset in your own Drive
drive.mount('/gdrive', force_remount=True)
Execution output
0KB
	Stream
		Mounted at /gdrive

Code cell <m6f5cvPq_aYr>
# %% [code]
### Hyperparameters

# The root dir have to point to the folder that cointains the database
root_dir = "/gdrive/My Drive/..."

# Data Type
datatype = "EEG"

# Sampling rate
fs = 256

# Select the useful par of each trial. Time in seconds
t_start = 1.5
t_end = 3.5

# Subject number
N_S = 1   #[1 to 10]


Code cell <7fQzTOUK1lTn>
# %% [code]
#@title Data extraction and processing

# Load all trials for a sigle subject
X, Y = extract_data_from_subject(root_dir, N_S, datatype)

# Cut usefull time. i.e action interval
X = select_time_window(X = X, t_start = t_start, t_end = t_end, fs = fs)

Code cell <9ohrUvI8pip3>
# %% [code]
print("Data shape: [trials x channels x samples]")
print(X.shape) # Trials, channels, samples

print("Labels shape")
print(Y.shape) # Time stamp, class , condition, session

Text cell <UH40Uwz-09d2>
# %% [markdown]
## Create the different groups for a classifier. A group is created with one condition and one clase. 

Code cell <RwovCAQCrEme>
# %% [code]
# Conditions to compared
Conditions = [["Inner"],["Inner"]]
# The class for the above condition
Classes    = [  ["Up"] ,["Down"] ]

Code cell <RQgiafjjqshv>
# %% [code]
# Transform data and keep only the trials of interes
X , Y =  transform_for_classificator(X, Y, Classes, Conditions)

Code cell <ooabEqcspZ-X>
# %% [code]
print("Final data shape")
print(X.shape)

print("Final labels shape")
print(Y.shape) 
Execution output
0KB
	Stream
		Final data shape
		(100, 128, 508)
		Final labels shape
		(100,)


